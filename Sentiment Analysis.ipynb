{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1_Part_2_Anuvrat_Baruah.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu2bMKF2mAZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "7cd6372a-77d7-4904-fbea-f83efd0e87a6"
      },
      "source": [
        "# Import Required Libraries \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from collections import defaultdict\n",
        "from nltk import word_tokenize\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8VIIqBTrBQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Lemmatizer class for Count Vectorizer \n",
        "\n",
        "tag_map = defaultdict(lambda: wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "tag_map['N'] = wn.NOUN\n",
        "\n",
        "class LemmaTokenizer(object):\n",
        "\n",
        "  def __init__(self):\n",
        "   self.wnl = WordNetLemmatizer()\n",
        "\n",
        "  def __call__(self, text):\n",
        "   lemmatized = []\n",
        "   for token, tag in pos_tag(word_tokenize(text)):\n",
        "      lemmatized.append(self.wnl.lemmatize(token.lower(), tag_map[tag[0]]))\n",
        "\n",
        "   return lemmatized"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBu0nGhm0VeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Training and Validation Datasets\n",
        "train = pd.read_csv('training.csv')\n",
        "train.head()\n",
        "valid = pd.read_csv('valid.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj07YCihz0gL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Pipeline for Pre-processing and training\n",
        "text_classifier = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(lowercase=True, tokenizer=LemmaTokenizer())),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='log', penalty='l2',\n",
        "                          alpha=1e-3, random_state=23,\n",
        "                          max_iter=250, tol=None, learning_rate='optimal')),\n",
        "])\n",
        "\n",
        "text_classifier.fit(train['Review'], train['Sentiment'])\n",
        "\n",
        "predicted = text_classifier.predict(valid['Review'])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v_CDsSU1oUr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "094cb17b-b3e5-4364-be10-7d78be67f10c"
      },
      "source": [
        "# Evaluation Metrics\n",
        "# Accuracy\n",
        "report = metrics.classification_report(y_true=valid['Sentiment'], y_pred=predicted, output_dict=True)\n",
        "acc = report['accuracy']\n",
        "print(\"Accuracy\",round(acc*100,3),'%')\n",
        "\n",
        "# F1-Score\n",
        "f1 = round(metrics.f1_score(y_pred=predicted, y_true=valid['Sentiment'], average='macro'), 3)\n",
        "print(\"F1-Score:\", f1 )\n",
        "\n",
        "# Confusion Matrix \n",
        "matrix = pd.DataFrame(metrics.confusion_matrix(y_pred=predicted, y_true=valid['Sentiment']))\n",
        "matrix.columns = ['Negative', 'Neutral', 'Positive']\n",
        "confusion = matrix.rename(index={0: 'Negative', 1: 'Neutral', 2: \"Positive\"})\n",
        "print(\" Confusion Matrix:\")\n",
        "print(confusion)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 70.339 %\n",
            "F1-Score: 0.697\n",
            " Confusion Matrix:\n",
            "          Negative  Neutral  Positive\n",
            "Negative        28       14         6\n",
            "Neutral          4       21         7\n",
            "Positive         1        3        34\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}